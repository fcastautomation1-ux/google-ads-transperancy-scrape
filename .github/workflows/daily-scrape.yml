name: 24/7 Google Ads Scraping

on:
  schedule:
    # Runs 4 times per day (every 6 hours) for 24/7 coverage
    # Each run processes for 5h 55m, then stops for 5 minutes before next run
    # Pakistan Time is UTC+5
    # Run 1: 5:00 AM PKT (00:00 UTC)
    - cron: '0 0 * * *'
    # Run 2: 11:00 AM PKT (06:00 UTC)
    - cron: '0 6 * * *'
    # Run 3: 5:00 PM PKT (12:00 UTC)
    - cron: '0 12 * * *'
    # Run 4: 11:00 PM PKT (18:00 UTC)
    - cron: '0 18 * * *'
  workflow_dispatch: # Allows manual triggering
  repository_dispatch:
    types: [sheet_update]

concurrency:
  group: scraping-group
  cancel-in-progress: true

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 355 # 5 hours 55 minutes - stops before 6-hour GitHub limit
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'
      
      - name: Install dependencies
        run: npm ci
      
      - name: Create credentials file
        run: |
          cat > credentials.json << EOF
          ${{ secrets.GOOGLE_CREDENTIALS }}
          EOF
        shell: bash
      
      - name: Log run start
        run: |
          echo "ğŸš€ Starting scraping run at $(date)"
          echo "â° This run will process URLs for up to 5h 55m"
          echo "ğŸ”„ Next run will start in 6 hours"
      
      - name: Run scraping script
        run: node agent.js
        env:
          GH_TOKEN: ${{ secrets.GH_TOKEN }}
      
      - name: Cleanup credentials
        if: always()
        run: rm -f credentials.json

